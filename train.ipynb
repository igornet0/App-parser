{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.amp import autocast, GradScaler\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d307cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import data_manager\n",
    "from backend.MMM import PricePredictorModel\n",
    "from backend.Dataset import DatasetTimeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e9494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedTrainer:\n",
    "    def __init__(self, config):\n",
    "        accelerator = Accelerator()\n",
    "        self.device = torch.device(accelerator.device)\n",
    "        self.config = config\n",
    "        self.scaler = GradScaler()\n",
    "        self.amp = config.get('mixed_precision', True)\n",
    "        \n",
    "        # Инициализация модели с оптимизированными параметрами\n",
    "        self.model = PricePredictorModel().to(self.device)\n",
    "        self.model = torch.compile(self.model)  # Pytorch 2.0 compilation\n",
    "        \n",
    "    def _get_dataloader(self, generator):\n",
    "        dataset = OptimizedTimeSeriesDataset(\n",
    "            generator,\n",
    "            seq_len=self.config['seq_len'],\n",
    "            pred_len=self.config['pred_len'],\n",
    "            batch_size=self.config['batch_size']\n",
    "        )\n",
    "        \n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=None,  # Уже батчируется в Dataset\n",
    "            pin_memory=False,\n",
    "            num_workers=self.config['num_workers'],\n",
    "            persistent_workers=True,\n",
    "            prefetch_factor=2\n",
    "        )\n",
    "\n",
    "    def _train_epoch(self, train_loader, optimizer):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for x, y, time_x in train_loader:\n",
    "            x = x.to(self.device, non_blocking=True)\n",
    "            y = y.to(self.device, non_blocking=True)\n",
    "            time_x = time_x.to(self.device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with autocast(enabled=self.amp):\n",
    "                preds = self.model(x, time_x)\n",
    "                loss = vectorized_quantile_loss(preds, y)\n",
    "            \n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.scaler.step(optimizer)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            total_loss += loss.item() * x.size(0)\n",
    "        \n",
    "        return total_loss / len(train_loader.dataset)\n",
    "\n",
    "    def train(self):\n",
    "        train_gen, val_gen = self.data_manager.get_generators()\n",
    "        \n",
    "        train_loader = self._get_dataloader(train_gen)\n",
    "        val_loader = self._get_dataloader(val_gen)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config['lr'],\n",
    "            weight_decay=self.config['weight_decay'],\n",
    "            fused=True  # Использование fused implementation\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.config['lr'],\n",
    "            total_steps=self.config['epochs'] * len(train_loader),\n",
    "            pct_start=0.3\n",
    "        )\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(self.config['epochs']):\n",
    "            train_loss = self._train_epoch(train_loader, optimizer)\n",
    "            val_loss = self._evaluate(val_loader)\n",
    "            \n",
    "            # Обновление планировщика\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Логирование и early stopping\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(self.model.state_dict(), \"best_model.pth\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.config['patience']:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break\n",
    "\n",
    "            print(f\"Epoch {epoch+1:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for x, y, time_x in dataloader:\n",
    "            x = x.to(self.device, non_blocking=True)\n",
    "            y = y.to(self.device, non_blocking=True)\n",
    "            time_x = time_x.to(self.device, non_blocking=True)\n",
    "            \n",
    "            with autocast(enabled=self.amp):\n",
    "                preds = self.model(x, time_x)\n",
    "                loss = vectorized_quantile_loss(preds, y)\n",
    "            \n",
    "            total_loss += loss.item() * x.size(0)\n",
    "        \n",
    "        return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# Пример конфигурации\n",
    "config = {\n",
    "    'data_paths': ['data/*.csv'],\n",
    "    'seq_len': 30,\n",
    "    'pred_len': 5,\n",
    "    'batch_size': 256,\n",
    "    'num_workers': 8,\n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'epochs': 100,\n",
    "    'patience': 7,\n",
    "    'mixed_precision': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851659cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Определение класса Dataset\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, time_features, seq_len=30, pred_len=5):\n",
    "        self.data = data\n",
    "        self.time_features = time_features\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len - self.pred_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.seq_len]\n",
    "        y = self.data[idx+self.seq_len:idx+self.seq_len+self.pred_len]\n",
    "        \n",
    "        time_x = self.time_features[idx:idx+self.seq_len]\n",
    "        return torch.FloatTensor(x), torch.FloatTensor(y), torch.FloatTensor(time_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc40783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Функция Quantile Loss\n",
    "def quantile_loss(preds, target, quantiles=[0.1, 0.3, 0.5, 0.7, 0.9]):\n",
    "    \"\"\"\n",
    "    Многомерная версия (для всех признаков)\n",
    "    Args:\n",
    "        preds: [batch, pred_len, num_quantiles, features]\n",
    "        target: [batch, pred_len, features]\n",
    "    \"\"\"\n",
    "    target = target.unsqueeze(2)  # [batch, pred_len, 1, features]\n",
    "    \n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = target - preds[..., i, :]  # [batch, pred_len, features]\n",
    "        loss = torch.max((q-1)*errors, q*errors)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    return torch.mean(torch.cat(losses, dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cf4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Загрузка данных (пример)\n",
    "def load_data():\n",
    "    # Загрузка своих данных\n",
    "    # data = ...  # [N, features]\n",
    "    # time_data = ...  # [N, 7] в формате [год, месяц, день, час, минута, секунда, день_недели]\n",
    "    # return train_data, val_data, train_time, val_time\n",
    "    \n",
    "    # Пример случайных данных\n",
    "    data = np.random.randn(1000, 5)\n",
    "    time_data = np.random.randint(2020, 2030, (1000, 7))\n",
    "    return data[:800], data[800:], time_data[:800], time_data[800:]\n",
    "\n",
    "train_data, val_data, train_time, val_time = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7565a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Инициализация модели и устройств\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PricePredictorModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e04a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "\n",
    "# Создание DataLoader\n",
    "train_dataset = TimeSeriesDataset(train_data, train_time)\n",
    "val_dataset = TimeSeriesDataset(val_data, val_time)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# 5. Настройка оптимизатора и планировщика\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "# 6. Цикл обучения\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4870ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.3453 | Val Loss: 0.2966\n",
      "Epoch 002 | Train Loss: 0.3021 | Val Loss: 0.2854\n",
      "Epoch 003 | Train Loss: 0.2989 | Val Loss: 0.2849\n",
      "Epoch 004 | Train Loss: 0.2989 | Val Loss: 0.2839\n",
      "Epoch 005 | Train Loss: 0.2975 | Val Loss: 0.2833\n",
      "Epoch 006 | Train Loss: 0.2976 | Val Loss: 0.2832\n",
      "Epoch 007 | Train Loss: 0.2973 | Val Loss: 0.2836\n",
      "Epoch 008 | Train Loss: 0.2973 | Val Loss: 0.2832\n",
      "Epoch 009 | Train Loss: 0.2969 | Val Loss: 0.2840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m time_x = time_x.to(device)\n\u001b[32m     10\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m loss = quantile_loss(preds, y)\n\u001b[32m     15\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/App-parser/backend/MMM/model.py:265\u001b[39m, in \u001b[36mEnhancedTimeSeriesModel.forward\u001b[39m\u001b[34m(self, x, time_data)\u001b[39m\n\u001b[32m    263\u001b[39m x = \u001b[38;5;28mself\u001b[39m.value_embed(x) + time_emb\n\u001b[32m    264\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pos_enc(x)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m enc_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m dec_out = \u001b[38;5;28mself\u001b[39m.decoder(enc_out)  \u001b[38;5;66;03m# [B, pred_len, d_model]\u001b[39;00m\n\u001b[32m    267\u001b[39m quantiles = \u001b[38;5;28mself\u001b[39m.quantile_proj(dec_out)  \u001b[38;5;66;03m# [B, pred_len, 3]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/App-parser/backend/MMM/model.py:116\u001b[39m, in \u001b[36mHierarchicalTransformerEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/App-parser/backend/MMM/model.py:135\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    132\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm1(x + \u001b[38;5;28mself\u001b[39m.dropout(attn_out))\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.conv:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     conv_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.transpose(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m)\n\u001b[32m    136\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.dropout(conv_out)\n\u001b[32m    138\u001b[39m ff_out = \u001b[38;5;28mself\u001b[39m.ffn(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/postgresdocker-MncL8gKv-py3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "    # Обучение\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y, time_x in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        time_x = time_x.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(x, time_x)\n",
    "        loss = quantile_loss(preds, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    \n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, time_x in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            time_x = time_x.to(device)\n",
    "            \n",
    "            preds = model(x, time_x)\n",
    "            loss = quantile_loss(preds, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "    \n",
    "    # Расчет средних потерь\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Логирование\n",
    "    print(f\"Epoch {epoch+1:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729bedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Загрузка лучшей модели\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgresdocker-MncL8gKv-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
